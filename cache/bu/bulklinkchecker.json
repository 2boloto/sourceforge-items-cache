{"_id": "4f7096ffb9363c122c0001e6", "categories": {"audience": [], "database": [], "developmentstatus": [], "environment": [], "language": [], "license": [], "os": [], "topic": [], "translation": []}, "creation_date": "2012-03-26", "developers": [{"name": "Steff Watkins", "url": "http://sourceforge.net/u/stefw27/", "username": "stefw27"}], "external_homepage": "", "icon_url": null, "labels": [], "moved_to_url": "", "name": "bulklinkchecker", "preferred_support_tool": "wiki", "preferred_support_url": "", "private": false, "screenshots": [], "short_description": "A script to check a list of about 100 URLs is fairly easy to turn out. What happens when you have to check 100,000 URLs?\r\n\r\nRather than check the URLs serially the idea is to check a subset of the URLs in parallel. By having a group of URLs all being concurrently checked, calls to URLs that are slow to resolve, respond or timeout are less likely to block  calls to URLs which give a quick response.\r\n\r\nThis code is (a small) part of the [OpenUp Project](http://www.open-up.eu/).", "shortname": "bulklinkchecker", "socialnetworks": [], "status": "active", "summary": "Perl script that verifies many 1000's of URLs.", "tools": [{"label": "Wiki", "mount_point": "wiki", "name": "wiki"}, {"label": "Files", "mount_point": "downloads", "name": "files"}, {"label": "Code", "mount_point": "code", "name": "git"}, {"label": "Tickets", "mount_point": "tickets", "name": "tickets"}, {"label": "Discussion", "mount_point": "discussion", "name": "discussion"}, {"label": "Summary", "mount_point": "summary", "name": "summary", "sourceforge_group_id": 732585}, {"label": "Reviews", "mount_point": "reviews", "name": "reviews"}, {"label": "Support", "mount_point": "support", "name": "support"}, {"label": "Activity", "mount_point": "activity", "name": "activity"}], "url": "http://sourceforge.net/p/bulklinkchecker/", "video_url": ""}
